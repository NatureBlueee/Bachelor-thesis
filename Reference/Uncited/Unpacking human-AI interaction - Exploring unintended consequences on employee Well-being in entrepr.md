

![Elsevier logo](935eed7aa61f7777f62cfc032e11bee9_img.jpg)

Elsevier logo

ELSEVIER

Contents lists available at ScienceDirect

Journal of Business Research

journal homepage: [www.elsevier.com/locate/jbusres](http://www.elsevier.com/locate/jbusres)![Journal of Business Research cover image](0538daaa5583c23e17db3a12f2281a55_img.jpg)

Journal of Business Research cover image

![Check for updates icon](4f4b52340aaccb1bcf733468dca9ee03_img.jpg)

Check for updates icon

# Unpacking human-AI interaction: Exploring unintended consequences on employee Well-being in entrepreneurial firms through an in-depth analysis<sup>∗</sup>

Jianwen Zheng<sup>a</sup>, Justin Zuopeng Zhang<sup>b</sup>, Muhammad Mustafa Kamal<sup>c,d,\*</sup>, Xiaoyang Liang<sup>a</sup>,  
Ebtesam Abdullah Alzeby<sup>b</sup>

<sup>a</sup> International Business School Suzhou, XJ un, Hoxtong-Liverpool University, China

<sup>b</sup> Department of Management, Coggin College of Business, University of North Florida, USA

<sup>c</sup> Operations and Analytics, Management Department, University of Exeter Business School, United Kingdom

<sup>d</sup> Secondary Affiliation - The School of Business, University of Jordan, Jordan

<sup>e</sup> College of Education and Human Development, Princess Noorah bin Abdulrahman University, P.O. Box 84428, Riyadh 11671, Saudi Arabia

## ARTICLE INFO

### Keywords:

Human-AI interaction  
Unintended consequences  
Employee well-being  
Entrepreneurial firms

## ABSTRACT

This study explores the influence of AI-based HRM systems on employee well-being in seasoned entrepreneurial firms through a comparative longitudinal case study of six high-technology ventures. The findings reveal four main shadow experiences associated with AI-based HRM systems, including the erosion of interpersonal autonomy, surveillance-induced precarity, algorithmic bias dilemma, and personalized discontentment. These experiences contribute to three distinct categories of well-being shadows: psychological alienation, physical adaptive overload, and social marginalization. This study clarifies the complex mechanisms linking shadow experiences to well-being outcomes and identifies enablers that can mitigate adverse effects, such as agility and personal growth, streamlined efficiency and harmony, and resource empowerment and engagement. It also proposes actionable pathways for employees to address and overcome these shadows, including deepened introspection, empowered inner power, and refined resourcefulness. The findings provide novel insights into the dual-edged nature of human-AI interaction and offer insights for promoting sustainable well-being in the evolving workplace environment.

## 1. Introduction

The integration of Artificial Intelligence (AI) and algorithmic methodologies into Human Resource Management (HRM) represents a significant paradigm shift, redefining operational efficiency and enhancing strategic decision-making processes (Awan et al., 2022; Akhtar et al., 2023; Chowdhury et al., 2023). This advancement extends beyond the automation of routine administrative tasks, enabling HR professionals to adopt a more strategic focus on transforming workforce dynamics. Existing literature posits that AI has a profound impact on workforce demographics, the nature and structure of jobs, and interactions between employers and employees. Moreover, AI facilitates the integration of technology with human roles, fostering greater job satisfaction and

enabling personalized work experiences (Connelly et al., 2021; Chowdhury et al., 2023; Rodgers et al., 2023).

To conceptualize these impacts, scholars have employed theoretical frameworks such as the Big Five personality traits, organizational justice, and socio-technical systems. These frameworks provide critical insights into how AI influences individual behaviors and organizational dynamics, establishing connections to broader HRM outcomes (Pan & Froese, 2023; Prikshtal et al., 2023). Empirical research underpinned by these theoretical perspectives highlights the positive implications of AI across key HRM functions. These include the optimization of recruitment processes, enhanced opportunities for employee development, increased operational efficiency, and the improved effectiveness of performance management systems (Ore & Sposato, 2022; Malik et al.,

\* This article is part of a special issue entitled: 'AI and Algorithmic HRM' published in Journal of Business Research.

<sup>∗</sup> Corresponding author.

E-mail addresses: [jianwen.zheng02@sjfu.edu.cn](mailto:jianwen.zheng02@sjfu.edu.cn) (J. Zhang), [justin.zhang@unf.edu](mailto:justin.zhang@unf.edu) (J.Z. Zhang), [m.m.kamal@exeter.ac.uk](mailto:m.m.kamal@exeter.ac.uk) (M.M. Kamal), [Xiaoyan.Liang@xjtu.edu.cn](mailto:Xiaoyan.Liang@xjtu.edu.cn) (X. Liang), [eaalzoway@pmu.edu.sa](mailto:eaalzoway@pmu.edu.sa) (E.A. Alzeby).

2023; Grewal et al., 2023; Shaikh et al., 2023; Yang, 2022; Abubakar et al., 2019; Robert et al., 2020).

Recent research highlights the significant influence of AI on worker well-being, encompassing factors such as autonomy, sense of purpose, cognitive load, and job security (Konuk et al., 2023; Nazareno & Schiff, 2021; Shaikh et al., 2023). These effects stem from the capacity of AI systems to reconfigure task execution, reshape job roles, and alter employees' perceptions of control over their work. On the one hand, some studies highlight AI's potential to enhance employee well-being by automating repetitive tasks, reducing cognitive burden, and delivering personalized support, which collectively contributes to improved mental health, resilience, and job satisfaction (Dutta & Mishra, 2024; Ho et al., 2022; Malik et al., 2023; Xiao et al., 2023; Zahoor et al., 2022). On the other hand, emerging evidence points to adverse consequences, such as diminished autonomy and perceived injustice, often attributed to heightened algorithmic oversight and control mechanisms (Kinowska & Sienkiewicz, 2023). These contrasting findings emphasize the complexity of AI's role in shaping the modern workplace and its implications for employee well-being.

Although existing studies have explored the potential unintended consequences of AI, they primarily focus on identifying these effects rather than understanding how and why such unintended consequences are associated with employee well-being. This limitation is further influenced by the reliance on quantitative approaches, which often focus on observable relationships but may not fully capture the underlying mechanisms and processes behind these impacts. Additionally, these studies frequently overlook the broader organizational context, which plays a critical role in shaping and mediating the relationship between AI implementation and employee experiences.

To address these limitations, this study adopts qualitative methods to provide a deeper and more nuanced understanding of the unintended consequences of AI-based HRM systems. By examining the processes and mechanisms through which these consequences influence well-being and by situating the analysis within the organizational context, this research aims to offer a more holistic perspective on the systemic and dynamic nature of these effects. Therefore, this study aims to address the following research question: How and why do the unintended consequences of AI-based HRM systems influence employee well-being within the organizational context? The significance of this study lies in its potential to bridge the gap between identifying unintended consequences and understanding their root causes, thereby advancing theoretical insights and offering practical strategies for organizations to mitigate adverse effects while fostering employee well-being.

To explore the research question, this study employs socio-technical system theory to explore the dynamic interactions between employees and AI-based HRM systems, focusing on how these interactions influence employee well-being. This theory is particularly suited for examining the interplay between technological and social elements within organizations, offering comprehensive perspectives to analyze the complexities of AI integration. Seasoned entrepreneurial firms are selected as the research context for qualitative data collection and analysis because they represent a unique combination of innovation and experience. These firms have typically matured beyond the initial startup phase, enabling them to offer insights into the long-term impacts of AI adoption on organizational practices and employee well-being. Additionally, their ability to navigate uncertainty and embrace cutting-edge technologies makes them an ideal setting to study how organizations integrate AI-based HRM systems while managing social and technological challenges.

This study makes several theoretical contributions. First, it introduces socio-technical system theory to examine the dynamic interactions between employees and AI-based HRM systems. This approach shifts the focus from static, quantitative analyses to a deeper exploration of the complex and evolving interplay between humans and technology. Second, the study highlights the darker aspects of AI-HRM interactions, emphasizing their dynamic nature and contributing to a

more nuanced understanding of how AI impacts employee well-being. Third, it identifies the underlying mechanisms through which AI-based HRM systems influence employee well-being, addressing the need for a comprehensive and context-sensitive framework to explain these impacts. Finally, the research offers actionable enablers of change and pathways to mitigate the unintended consequences, providing practical solutions to foster resilient and psychologically healthy workplaces.

The structure of this paper is as follows. Following the introduction, the theoretical foundation is established, and the methodology and data analysis are described. The findings are then presented, followed by a discussion that addresses theoretical contributions, practical implications, and research limitations. The paper ends with recommendations for future research directions.

## 2. Theoretical background

### 2.1. Socio-technical systems theory

AI-based HRM systems leverage artificial intelligence to automate and enhance various human resource management functions, including recruitment, task allocation, performance management, and employee development (Halid et al., 2024; Pan & Froese, 2023). These systems are designed to improve organizational efficiency and decision-making processes (Prikshat et al., 2023). However, their implementation may also lead to unintended negative consequences, such as increased surveillance and data-driven practices, which can adversely affect employee well-being. Socio-technical systems theory provides a valuable lens for examining the interplay between technological systems and social dynamics, emphasizing the importance of balancing human and technological dimensions within organizations (Manz & Stewart, 1997; Makarius et al., 2020). This theoretical approach is particularly relevant to this study, as it offers a robust framework for analyzing the unintended consequences of AI-based HRM systems, with a specific focus on their impact on employee well-being.

Socio-technical systems theory underscores the interconnectedness and mutual dependence of human and technical subsystems within organizational contexts (Manz & Stewart, 1997; Münch et al., 2022). The successful implementation of AI-based HRM systems requires a nuanced understanding of the dynamic interactions between humans and technology. Ensuring that these systems are designed and integrated in ways that support both technological advancements and human resource management objectives is critical. This relationship is shaped by socio-technical transformation, a process that governs the co-evolution of technological and social systems to achieve organizational goals (Sony & Naik, 2020; Yu et al., 2023).

First, socio-technical systems theory emphasizes the principle of joint optimization, which advocates for the simultaneous alignment and enhancement of technological systems (e.g., tools, algorithms, and processes) and social systems (e.g., organizational roles, interpersonal relationships, and employee well-being) (Makarius et al., 2020). In the context of AI-based HRM systems, joint optimization requires designing processes in ways that balance operational efficiency with employee engagement and satisfaction. For instance, AI tools deployed for performance evaluations or task assignments must promote transparency and fairness, thereby fostering trust and collaboration among employees rather than resistance or dissatisfaction.

Second, the theory highlights the importance of adaptability, which allows organizations to remain flexible and responsive to changes in technological and social environments (Sony & Naik, 2020). For AI-based HRM systems, adaptability entails integrating AI technologies into existing workflows in a way that minimizes disruption for employees. This requires assessing and improving the flexibility of both the technological infrastructure and organizational processes to accommodate shifting roles, responsibilities, and employee needs. By fostering adaptability, organizations can mitigate potential resistance and ensure

that employees remain aligned with evolving workplace dynamics.

Third, socio-technical systems theory prioritizes a human-centric design approach, which emphasizes the importance of addressing user needs during the development and implementation of technological systems (Chowdhury et al., 2022; Guest et al., 2022). In the context of AI-based HRM systems, this involves actively considering employee perspectives and reactions to new technologies. For example, AI systems designed to monitor employee performance must avoid imposing excessive surveillance or fostering mistrust. Instead, they should focus on creating a supportive and collaborative work environment that prioritizes employee well-being and job satisfaction. Thoughtful integration of new technologies ensures that technological advancements contribute to a positive and productive work atmosphere.

The key assumptions of socio-technical systems theory provide a robust framework for this study, enabling a detailed exploration of the unintended consequences of AI-based HRM systems on employee well-being. By examining the interplay between shadow experiences, technological design, and social dynamics, this approach helps identify the mechanisms through which unintended consequences emerge. Ultimately, socio-technical systems theory allows for a comprehensive understanding of the challenges associated with AI-based HRM systems, offering insights into how organizations might mitigate these adverse effects while fostering a more resilient and human-centered workplace.

### 2.2. AI in human resource management

AI-based HRM systems integrate artificial intelligence technologies into HRM frameworks to enhance data processing and analysis, thereby improving decision-making and problem-solving across operational, relational, and transformational dimensions of HRM (Prikshtat et al., 2023; Prikshtat, Islam et al., 2023). Scholars have employed various theoretical perspectives to investigate the implications of these systems within organizational contexts (Prikshtat et al., 2023; Prikshtat, Islam et al., 2023). For instance, psycho-social theories, such as behavioral decision theory, psychological ownership, and social exchange theory, have been used to examine the psychological and social dimensions of HRM, particularly in areas such as job evaluation, training, performance management, and recruitment. Similarly, innovation diffusion theories, including transaction cost theory, have been applied to explore the adoption and implementation of AI technologies in HRM, with a focus on training and development. Additionally, expert system theories, such as the expert system model, have been employed to emphasize the design and application of intelligent systems to improve HRM functions.

The majority of existing studies have predominantly concentrated on the positive impacts of AI-related technologies in enhancing efficiency and decision-making across various HRM domains (Prikshtat, Islam et al., 2023). For example, in recruitment, AI and data mining technologies optimize selection processes, improving accuracy and reducing time-to-hire (Van Esch & Black, 2019). In training, AI facilitates crisis decision-making and supports employee re-skilling through personalized learning approaches (Cheng & Hackett, 2021). In performance management, AI ensures fair evaluation through data-driven insights and predictive analytics (Robert et al., 2020). Talent management also benefits from AI's ability to enhance employee capabilities and bridge skill gaps (Guinan et al., 2019). Beyond these applications, AI supports job design, evaluation, and employee engagement through digital tools, improving retention and overall workforce satisfaction (Prikshtat, Islam et al., 2023). These examples underscore the transformative potential of AI in improving HRM processes and outcomes.

Other studies have investigated the outcomes of AI-based HRM systems, highlighting their role in advancing training programs, performance management, and talent development. For instance, AI enhances training by offering personalized programs and leveraging HR analytics to align with individual employee needs (Maity, 2019). In performance management, it addresses issues such as knowledge hiding while facilitating workplace monitoring and providing actionable insights to

supervisors (Abubakar et al., 2019). In talent management, AI bridges capability gaps and enhances organizational performance by employing advanced analytics to identify and develop talent (Leonardi & Contractor, 2018). Overall, these studies demonstrate AI's capacity to significantly improve HR efficiency and effectiveness.

In addition to its benefits, scholars have also examined the ethical challenges and unintended consequences associated with AI-based HRM systems. For example, in recruitment and selection, AI is often employed to reduce unconscious human biases and ensure fairness in the evaluation of job applicants (Cheng & Hackett, 2021). Ethical considerations in talent management have also been emphasized, with studies advocating for responsible AI practices to prevent adverse outcomes (Prikshtat, Islam et al., 2023). However, the adoption of AI in HRM is not without challenges. For instance, integrating blockchain technology into recruitment processes, addressing barriers to AI adoption, and navigating social and organizational considerations present significant obstacles (Cubric, 2020; Prikshtat, Islam et al., 2023). While some of these studies acknowledge the challenges associated with AI-based HRM systems, they tend to focus on technological and organizational barriers rather than employee-level impacts.

Despite this growing body of research, the extant literature predominantly highlights the positive functions and outcomes of AI-driven HRM systems, such as improving recruitment efficiency, personalizing training initiatives, and refining performance evaluation processes. These implementations are widely recognized for their role in enhancing organizational productivity and optimizing HR operations. However, there remains a notable paucity of research addressing the unintended consequences of these technologies within HRM frameworks. While certain studies have explored challenges in recruitment, performance management, and talent development, they primarily emphasize organizational benefits rather than individual-level consequences.

This gap is particularly pronounced in the context of employee well-being, which remains an underexplored area in the discourse on AI-based HRM systems. The limited focus on how these technologies affect employees' psychological, physical, and social well-being leaves a critical void in the literature. Addressing this gap is essential for developing a more holistic understanding of the dual impacts of AI within HRM—both its benefits and its unintended consequences. By examining the unintended consequences of AI-based HRM systems, particularly their impacts on employee well-being, this study seeks to contribute to a more comprehensive perspective.

### 2.3. AI-based HRM systems and employee well-being

The concept of employee well-being has evolved from a narrow focus on physical health to a comprehensive framework that integrates psychological, physical, and social dimensions (Inceoglu et al., 2018; Berries et al., 2020). The OECD underscores the importance of subjective well-being, emphasizing the diverse experiences and overall life satisfaction of individuals (OECD, 2023; Guest, 2017). Within the workplace, well-being is typically categorized into three interconnected domains: psychological, physical, and social (Fox et al., 2022). Psychological well-being pertains to emotional and cognitive engagement, which fosters job satisfaction, motivation, and a sense of fulfillment (Ryff et al., 1995; Warr, 1990). Physical well-being focuses on ergonomic workplace design, adherence to safety protocols, and work-life balance, all of which contribute to employee health and productivity (Inceoglu et al., 2018). Social well-being emphasizes the quality of interpersonal relationships, inclusivity, and organizational culture, fostering collaboration and a sense of community within the workplace (Warr, 1990; Guest, 2017). This integrated approach is essential for developing a healthy, engaged, and productive workforce.

Recent research has begun to examine the effects of AI technologies on employee well-being, with findings revealing both advantages and unintended consequences. On the positive side, AI has been shown to improve efficiency and support workplace experiences. For instance, Xu,

Xue, and Zhao (2023) surveyed 268 employees, finding that AI opportunities positively influence employee well-being through informal workplace learning, although this effect is moderated by perceptions of unemployment risk. Similarly, Shaikh et al. (2023) studied 184 health-care professionals in Pakistan, and found that AI enhances productivity by fostering positive attitudes and behaviors, which in turn improve employee well-being and facilitate knowledge sharing.

Conversely, other studies highlight the unintended consequences of AI technologies, such as increased job insecurity and health-related challenges. Gull, Ashfaq, and Aslam (2023), using data from 253 employees across industries in Pakistan, found that AI identity threats exacerbate cognitive job insecurity, which negatively affects employee well-being. Their findings suggest that training programs can help mitigate these impacts. Similarly, Nazareno and Schiff (2021) analyzed data from 402 occupations and observed that while higher automation risk reduces stress, it also worsens health outcomes and decreases job satisfaction. These findings suggest that the impacts of AI technologies are multifaceted and call for further exploration of their diverse and contradictory effects on employees.

Taken together, the existing literature largely emphasizes the benefits of AI technologies in HRM, with limited focus on their unintended consequences. When challenges are addressed, they are often framed as technical or implementation barriers rather than as critical impacts on employees. Furthermore, much of the existing research treats well-being as an aggregate concept, neglecting the distinct dimensions of psychological, physical, and social well-being. This lack of specificity risks obscuring the nuanced impacts of AI technologies that may vary across these dimensions. Additionally, most studies rely on quantitative methods, which often emphasize statistical relationships between AI technologies and overall well-being. While such approaches provide useful insights, they are limited in their ability to capture the contextual and experiential nuances that qualitative research can reveal.

To address these gaps, this study adopts a qualitative inductive approach to investigate how AI-based HRM systems adversely affect employee well-being, as well as to identify the mechanisms through which these impacts occur in seasoned entrepreneurial firms. By focusing on the psychological, physical, and social dimensions of well-being, this study aims to provide a more nuanced and comprehensive understanding of the unintended consequences of AI technologies. Grounded in socio-technical systems theory, the research delves into the interactions between employees and AI-based HRM systems, uncovering the mechanisms that drive adverse outcomes.

This study seeks to thoroughly examine employee experiences with AI-based HRM systems in established entrepreneurial firms, focusing on how these systems influence well-being. Particular attention is paid to the adverse impacts of AI-based HRM systems on the psychological, physical, and social dimensions of well-being to provide a detailed understanding of these effects. Furthermore, the research investigates the mechanisms through which AI-based HRM systems generate unintended consequences, offering insights into the complex dynamics of human-technology interactions.

## 3. Methodology

### 3.1. Research design

To address the research question, the researcher has chosen a grounded theory methodology supported by a multiple case study analysis, as recommended by Eisenhardt (1989; 2021). According to Eisenhardt and Graebner (2007) and Yin (2003), such a qualitative exploratory research approach facilitates exploration of both the “how” question—how AI-based HRM systems adversely affect employee well-

being—and the “why” question—through which mechanisms these impacts are generated in seasoned entrepreneurial firms (Tracy, 2024). Additionally, a multiple-case study strategy allows for cross-case comparison (Cannas et al., 2024), enabling the development of more robust and generalizable theories than single-case studies (Eisenhardt & Graebner, 2007).

### 3.2. Case selection and sample description

This study conducted longitudinal case studies in six seasoned entrepreneurial firms that are actively engaging in implementing AI-based HRM systems. These firms were selected from diverse high-technology industries, including hardware manufacturing, software development, networking hardware, semiconductors, digital healthcare, and telecommunications. The selection process was guided by theoretical and purposive sampling logic (Eisenhardt, 1989; Alam, 2021). This approach involved identifying firms that could provide rich insights into the research questions (Halkias et al., 2022), ensuring diversity across industries to capture a wide range of AI-based HRM implication experiences and impacts on employee well-being.

The process involved several stages to ensure the selection of relevant and diverse cases. We began by compiling a list of 65 potential firms from the Beijing High-Quality SME Directory provided by The People's Government of Beijing Municipality. The initial screening criteria required firms to have a demonstrable track record of implementing AI in HRM systems, belong to different high-technology industries, and possess about 10 years of operational experience. The list was refined through analysis of company profiles, news articles, and case studies to assess their engagement with AI-based HRM. We approached these firms through networking, leveraging investor networks, entrepreneurial social media, and personal connections. This effort resulted in opportunities to engage with 11 firms.

We engaged in informal conversations with senior managers to confirm their willingness to participate in this academic research project. During these discussions, we outlined our research questions, objectives, and aims to ensure a clear understanding of our research context. We also assessed whether each firm met the following selection criteria: having a formal HRM department and system in place for over five years, at least three years of experience with AI and algorithmic HRM practices and employing more than 50 people to provide a substantial pool of potential informants. Additionally, we consulted two investor experts with extensive experience in financing and facilitating firm growth across various industries. Their insights helped validate the shortlist of 11 firms by identifying those with significant AI implementation in HRM systems. We further assessed the feasibility of each shortlisted firm, considering factors such as willingness to participate, data accessibility, and potential for longitudinal analysis. After several rounds of discussions and rigorous evaluation, six firms were selected. Each firm was chosen to ensure a representative mix of industries and varied approaches to AI-based HRM systems.

The study examines the six selected firms, each utilizing AI-based HRM systems to revolutionize operations across diverse high-tech industries. Founded between 2010 and 2012, these companies have led the integration of AI into HRM, with implementations starting between 2015 and 2018. They deploy AI technologies like automated resume screening with natural language processing to streamline recruitment and predictive analytics to enhance strategic decisions on employee performance and retention. AI-powered chatbots improve employee experience by providing instant responses and simplifying onboarding, while performance management tools offer personalized feedback through continuous tracking. Task management systems automate allocation and monitor progress, boosting efficiency, and engagement

platforms use sentiment analysis to gauge satisfaction and morale. These firms span diverse sectors—including hardware manufacturing, networking hardware, semiconductors, software development, digital healthcare, and telecommunications—providing a comprehensive view of AI-based HRM systems across different industrial contexts. This diversity enriches our analysis and strengthens the development of robust, accurate theories (Yin, 2009).

To further facilitate comparative analysis across the selected firms, we requested approximate sales growth data from each firm for the past three years. We assured them this information would remain confidential and not be reported in our study; it was solely used to categorize the firms for analysis. We identified two high-growth firms (ENT A and ENT B) with the strongest sales growth, two firms (ENT C and ENT D) with moderate growth, and two firms (ENT E and ENT F) showing the least growth, categorized as the low-growth group (see Table 1).

### 3.3. Data collection

Utilizing a case study strategy (Eisenhardt and Graebner, 2007; Yin, 2003), we adopted a multifaceted data collection approach to gain rich, nuanced insights, significantly enhancing the rigor of our theoretical development. Our methodology involved concurrent and iterative stages, facilitating the construction of detailed longitudinal case histories for each firm. This comprehensive approach allowed for an in-depth exploration of AI-based HRM systems, elucidating the complex mechanisms and underlying dynamics throughout the study.

The primary data sources consisted of insights gathered through comprehensive semi-structured interviews with employees from the selected firms. According to Hennink et al. (2020) and Patton (2015), all informants were selected using theoretical and purposive sampling logic. We asked the firms to suggest six employees who had been with the company for at least five years and had experience and knowledge of AI-based HRM systems. Conducted over 13 months (July 2022 to July 2023), we held 72 formal sessions involving 36 employees from the six selected firms, with 6 participants from each organization. These interviews, lasting from 50 to 150 min, were conducted both face-to-face and online, providing in-depth perspectives on AI-based HRM systems. Additionally, we conducted 24 in-depth interviews with the founding CEOs and their HR managers (or co-founders, where applicable). Each CEO and HR manager participated in two interviews, ranging from 60 to 180 min, also using a mix of face-to-face and online formats. A detailed summary of the data sources is presented in Table 2.

In our data collection process, we adopted a structured approach for the initial round of interviews, using semi-structured questions as the foundation of our discussions. These questions were designed to establish a comprehensive profile of each participant, including inquiries such as: What is your current position within the company? How long have you been employed by the company? Could you describe the responsibilities and tasks associated with your role? This line of inquiry aimed to create a detailed backdrop of the interviewees' professional experiences and their engagement within the organization. After establishing this foundational context, we shifted our focus to explore participants' direct experiences and attitudes towards the firm's

integration of AI technologies in HRM. We posed reflective and thought-provoking questions to participants, such as: How would you describe your experiences and impressions of the firms' AI-based HRM tools and practices? Have there been any adjustments or shifts in your workflow or daily routines due to the implementation of these AI and algorithmic HRM systems? If so, please elaborate. What obstacles or challenges have you faced in adapting to these AI-based HRM systems? How has the implementation of AI-based HRM systems impacted your well-being, and why? These questions were meticulously designed to encapsulate various facets of employee well-being, including psychological, physical, and social dimensions, providing a holistic view of the workforce's state in the context of technological change. For founders and HR managers, our questions were more strategic and evaluative, probing into the leadership's navigation through the technological shift and its repercussions: How would you characterize the transition from traditional HR practices to the adoption of AI and algorithm-driven HR systems? Could you assess the benefits and drawbacks experienced by employees as a result of integrating AI and algorithmic HR practices? What potential strategies or policies might be considered to mitigate any unintended consequences stemming from these technological advancements in the workforce?

### 3.4. Data analysis

Using an inductive exploratory research approach, we analyzed data to understand how AI-based HRM practices influence well-being in seasoned entrepreneurial firms and through which mechanisms. Our systematic process involved several key steps. Initially, researchers manually coded the data for deep engagement, followed by an additional round of coding using NVivo software. This combination enhanced the reliability and validity of our findings by ensuring consistency and providing a comprehensive analysis.

**Step 1: Initial longitudinal case study.** Prior to implementing grounded theory coding, researchers reviewed interview transcripts, archival documents, and observational notes from company visits and semi-structured interviews to construct a longitudinal narrative for each firm. This comprehensive data integration allowed for the identification of temporal sequences in AI-based HRM implementations and provided insights into employees' adoption experiences. The triangulation of these data sources facilitated a robust understanding of AI-based HRM processes. The narratives were shared with the respective firms for feedback and reviewed by two investor experts involved in sample selection for further validation. This iterative approach enhanced our understanding of AI-based HRM practices within each firm.

**Step 2: Grounded theory coding approach.** Following the analysis approach of grounded theory (Glaser & Strauss, 2017), we conducted three coding processes: open coding, axial coding and aggregate dimension extraction. During the open coding process, we employed a meticulous technique to examine and classify participants' verbatim comments. This process involved multiple iterations, resulting in the emergence of preliminary codes for each case. We engaged participants and industry experts by sharing these codes to gather insights and critiques. Their feedback informed subsequent coding rounds, refining and

**Table 1**  
Sample characteristics.

| Groups   | Ventures | Founding Year | Firm Location | AI-HRM Initiated Year | HR Department Established Year | Industry Sectors       | Founding Team Member Changed | No. of Employees | No. of Departments |
|----------|----------|---------------|---------------|-----------------------|--------------------------------|------------------------|------------------------------|------------------|--------------------|
| High     | ENT A    | 2011          | Beijing       | 2017                  | 2014                           | Hardware Manufacturing | Unchanged                    | 97               | 5                  |
|          |          |               |               |                       |                                | Networking Hardware    | Unchanged                    |                  |                    |
|          |          |               |               |                       |                                | Semiconductors         | Unchanged                    | 40               | 7                  |
| Moderate | ENT B    | 2012          | Beijing       | 2016                  | 2015                           | Semiconductors         | Unchanged                    | 56               | 6                  |
|          |          |               |               |                       |                                | Software               | Unchanged                    | 74               | 5                  |
|          |          |               |               |                       |                                | Development            | Unchanged                    |                  |                    |
| Low      | ENT C    | 2010          | Beijing       | 2018                  | 2013                           | Digital Health         | Unchanged                    | 68               | 7                  |
|          |          |               |               |                       |                                | Telecommunications     | Unchanged                    | 84               | 6                  |
| Low      | ENT D    | 2012          | Beijing       | 2016                  | 2014                           |                        |                              |                  |                    |
|          |          |               |               |                       |                                |                        |                              |                  |                    |

**Table 2**  
Summary of data Sources.

| Groups        | Ventures | Semi-Structured Interview |              | Informal Consultations                       |                     |                   |
|---------------|----------|---------------------------|--------------|----------------------------------------------|---------------------|-------------------|
|               |          | CEO                       | HR Directors | Employees with more than 5 years in the Firm | Informal Interviews | Summaries Checked |
| High          | ENT A    | 2                         | 2            | 12                                           | 4                   | 4                 |
|               | ENT B    | 2                         | 2            | 12                                           | 5                   | 4                 |
|               | ENT C    | 2                         | 2            | 12                                           | 5                   | 4                 |
| Moderate      | ENT D    | 2                         | 2            | 12                                           | 4                   | 4                 |
|               | ENT E    | 2                         | 2            | 12                                           | 7                   | 4                 |
|               | ENT F    | 2                         | 2            | 12                                           | 5                   | 4                 |
| Sub Total     |          | 12                        | 12           | 72                                           | 30                  | 24                |
| Overall Total |          | 96                        |              |                                              | 54                  |                   |

accurately representing participants' perspectives. For instance, narratives detailing experiences with AI and algorithmic HRM practices—such as “diminished in-person interaction with HR staff,” “erosion of human connection,” and “feeling governed by machines”—were directly coded from interview transcripts. Our coding framework evolved as we compared cases to identify commonalities and differences in employee experiences across scenarios. We expanded our cross-case analysis by exploring new combinations of interactions, leading to a refined set of recurring statements distilled into our initial codes (see Fig. 1).

During the axial coding process, we elevated initial codes to more conceptual second-order themes; this transition marked a progression from open to axial coding. It was at this juncture that we integrated our analysis with existing academic discourse, aiding the refinement of initial insights into these broader themes. This process was instrumental in distilling the nuances of employee discontent with AI-driven HRM practices. For instance, “erosion of human interaction” emerged as a pivotal second-order theme encapsulating various first-order

observations such as “loss of personal touch,” “feeling governed by algorithms rather than people,” “diminished human connection,” “anonymity in AI-mediated dialogues,” and “decreased direct contact with HR staff, fostering feelings of detachment.” Once we had established the second-order themes, we meticulously reassessed and debated them to confirm their alignment with the original codes (see Fig. 1).

During the aggregate dimension extraction process, we advanced from detailed second-order themes to overarching aggregate dimensions. At this stage, we explored the broader constructs indicated by the second-order themes. A comprehensive comparative review of the themes and their corresponding dimensions was conducted to verify the emergence of novel insights. For instance, we combined “erosion of human interaction,” “undermining of professional autonomy,” and “impact on work relationships” into a unified dimension termed “erosion of interpersonal autonomy.” To ensure rigor and relevance, we shared the complete framework, including primary codes, evolved theoretical themes, and aggregate dimensions, with the interviewees for feedback. We carefully analyzed their input to refine and finalize our

![](80530169c7b6298ce012a85b906caeb3_img.jpg)

Figure 1 illustrates the data structure of employees' shadow experience toward using AI and algorithmic HRM, organized into a hierarchical flowchart.

The flowchart starts with statements on various aspects of AI adoption and HRM practices, which lead to the following second-order themes:

- Erosion of Human Interaction
- Undermining of Professional Autonomy
- Impact on Work Relationships
- Process-Related Exhaustion
- Chronic Adaptation Stress
- Bias and Discrimination
- Legal and Ethical Ambiguity
- Decreased Engagement and Morale
- Complexity and Accessibility Issues
- Over-reliance on AI

These second-order themes further lead to the following aggregate dimensions:

- Erosion of Interpersonal Autonomy
- Algorithm Bias Dilemma
- Personalised Discontentment

Specific statements are listed below the flowchart:

- Statements on “have reduced face-to-face time with HR professionals, leading to a sense of isolation”; “diminish the personal touch”; “a feeling of being managed by machines rather than humans”; “reducing meaningful human engagement”; “lost in AI-mediated communications”.
- Statements on “AI task monitoring leads to the feelings of micromanagement and loss of work control”; “limit my ability to make independent decisions”; “dictate workflows and priorities can undermine a sense of agency”; “There is a sentiment among us that AI is overly deterministic, leaving little room for self-directed career development”; “dictating when and how I work”.
- Statements on “can disrupt the natural give-and-take dynamic between team members, leading to friction”; “matchmaking for collaboration can overlook personal dynamic for team synergy”; “Excessive AI use in HR can alienate us from the coworker community”; “led to a breakdown in the informal networks that are key to a cohesive workplace”; “AI standardization may erode personal acknowledgement viral for work bonds”.
- Statements on “Having concerns about constant surveillance and personal privacy”; “felt my privacy is compromised by AI systems that tracked my every move, both online and offline”; “big brother is watching”; “messages for sentiment analysis”.
- Statements on “was anxious about the pace of AI adoption”; “worry over future employability in my roles”; “Pressure to complete with AI for tasks, fearing we might not measure up”; “Stress over the need for continual learning and adaptability”; “challenging my unique value”; “being outpaced by technology”; “fears of widespread job displacement”.
- Statements on “I was aware that AI can perpetuate existing biases”; “lack of transparency in decision-making processes left us skeptical about fairness and objectively”; “mistrust in AI HR fairness”; “not accounting for the complexity of human experiences”.
- Statements on “uncertainty about who is accountable for AI errors or biases in management”; “lack of clear regulations for AI HRM creates unease about its use in employee monitoring”; “doubt over the legality of AI’s role”; “concerns about the boundaries of AI surveillance in workplace”; “doubt about its alignment with ethical employment practices”.
- Statements on “felt undervalued”; “disengagement and a sense of being just a number of the AI system”; “AI’s inability to address emotional and psychological needs at work”; “diminish the meaningfulness of achievements”; “struggle to adapt...leading to burnout and disengagement”.
- Statements on “face a steep learning curve with complex AI HRM systems, leading to frustration and disconnection”; “causing feelings of inadequacy”; “felt overwhelmed by the constant need to adapt to advanced AI HR processes”; “the fear of error in using complex AI systems”.
- Statements on “overshadow my intuition and wisdom in critical decision-making”; “over-dependence on AI for leadership decisions”; “lacking in my personal growth”; “ignoring the unique needs”.

**Fig. 1.** Data structure of employees' shadow experience toward using ai and algorithm HRM.

![](c0843c6d138705289960d9f53a6e72a1_img.jpg)

Statement on "I feel like a number, not a unique individual"; "Without human contact, I question if my work is valued"; "makes me feel unsupported when I need it most"; "AI disregards my culture and work style"; "AI is HE has cooled and disconnected our workplace"; "AI mistakes could jeopardize my career"; "lack the nuances of human judgment and empathy".

Impersonal Job Dissatisfaction

Psychological Alienation

Statement on "I'm visible to the AI, it overlooks my story"; "AI's precision neglects human side"; "AI's impersonality removes workplace humanity"; "AI cannot grasp my career goals or experiences"; "Without human HR, I feel powerless"; "AI does not 'know me'; "AI does not see 'me' - just inputs and outputs"; "do not reflect individual life contexts"; "AI is disconnecting me from my role"; "The AI system's indifference threatens my individuality"; "Wide approach is indifferent to personal dynamics".

Systemic Depersonalization

Uncertainty Induced Anxiety

Statement on "AI's impact on my job security is a constant worry"; "AI's decisions cloud my career clarity"; "Unclear how AI judges my work, leaving me anxious"; "I fear unjust AI targeting without explanation"; "AI's unpredictable feedback keeps me tense"; "Job insecurity stems from AI's unclear decision"; "Doubts about my future here due to vague AI assessments"; "AI's fickle feedback unseems me"; "AI risks overlooking my value, provoking anxiety"; "leaves me unsettled".

Process Related Exhaustion

Physical Adaptive Overload

Statements on "Overwhelmed by AI-driven workflow demands"; "Exhausted from endless AI systems updates"; "AI's rigidity allows no breathing space"; "Drowning in AI's continuous data input"; "Pressed to keep up with AI's productivity"; "Multitasking with AI takes a toll"; "Weighed down by AI's task volume"; "AI's time pressures spark exhaustion".

Chronic Adaptation Stress

Statements on "Constantly adapting to AI protocols is overwhelming"; "The pace of AI change leaves me no room to settle"; "I'm worn out from the never-ending AI learning curve"; "AI's shifting demands create persistent tension"; "Struggling to keep pace with AI's transformation"; "The ongoing rush to adapt to AI leaves me feeling perpetually behind".

Process-Driven Isolation

Support Deficiency

Statements on "AI processes are disconnecting us at work"; "AI has replaced workplace camaraderie with screens"; "AI's automation has made work lonelier"; "Workplace community dimmed"; "AI makes me feel like a machine part"; "Limits casual interactions"; "AI's productivity push sidelines social interactions"; "Erasing human bonds"; "Stifling organic social exchanges".

Social Marginalization

Statements on "AI lacks human empathy and support"; "AI's guidance falls short on personal issues"; "Personal encouragement list to AI efficiency"; "Real understanding and support gap with AI HR"; "Cannot match the encouragement from a human network"; "Limit the community feedback loop"; "Do not facilitate the camaraderie that comes from shared experiences".

Procedural Fairness Skepticism

Statements on "Does not adequately weigh unique circumstances"; "AI's rigid rules neglect context in fairness"; "Skeptical of AI's nuanced decision-making"; "Concerned AI misses subtleties of justice"; "Wary of AI's non-intuitive performance assessment"; "AI cannot empathize with human fairness concepts"; "Judgement lacks human perspective"; "Ensure how AI's logic translates to equitable handling"; "Doubts about proper treatment".

Harnessing Personal Growth

Fostering Collaborative Individuality

Statements on "Improving from workplace challenges"; "Growing through reflection"; "Stress to development transformation"; "Mindfulness for balance"; "Growth mindset against obstacles"; "Adaptive to change"; "Mentorship for resilience".

Agility & Personal Growth

Statements on "Highlighting expertise within team dynamics"; "Using my individuality to fill gaps in team expertise"; "Combining personal drive with shared team ambitions"; "Excellence within a team frame"; "Independently contributing to team unity"; "Shaping my role for team synergy"; "Crafting my place in team architecture".

Cultivating Adaptive Assurance

Statements on "Embracing change for workplace agility"; "Flexibility navigating work uncertainties"; "Learning to pivot with new challenges"; "Proactively planning for disruption"; "Enhancing adaptability in evolving roles"; "Using adaptability for growth".

Streamlining Workflows and Mindfulness

Statements on "Optimizing tasks for better focus"; "Streamlining for mental clarity"; "Practicing present-minded productivity"; "Mindful breaks for performance upkeep"; "Prioritizing to manage energy"; "Refining routines for work-life balances".

Streamlined Efficiency & Harmony

Statements on "Tailoring work-life balance for personal resilience"; "Building a supportive career-personal network"; "Setting boundaries for well-being"; "Cultivating a resilient work-life mindset"; "Aligning professional growth with life goals"; "Using workplace resources for life balance".

Fostering Resilience Work-Life Ecosystem

Statements on "Embracing empathy for deeper team connection"; "Sharing team goals for unity"; "Contributing to a positive team atmosphere"; "Valuing team downtime for bonding"; "Organizing social events to enhance camaraderie".

Creating Team Connectivity & Bonding

Statements on "Staying informed on support systems"; "Contributing to a resourceful team environment"; "Ensuring resource transparency"; "Tapping into wellness programs for resilience"; "Learning response protocols for crises"; "Seeking training to handle stress"; "Informed about workplace aids".

Fortifying Resource Access & Response

Statements on "Fostering constructive dialogue"; "Valuing active listening and communication"; "Initiating stress-reducing problem solving"; "Encouraging constructive feedback for growth"; "Embracing tough talks for progress"; "Welcoming diverse viewpoints for better understanding"; "Nurturing team dialogue for collective resilience".

Fostering Constructive Dialogue

Resource Empowerment & Engagement

Fig. 2. Data structure of employees' well-being shadows.

![](c64e9e9f3b0b828a5f6ac70441877764_img.jpg)

Statements on "Improving from workplace challenges"; "Growing through reflection"; "Stress to development transformation"; "Mindfulness for balance"; "Growth mindset against obstacles"; "Adaptive to change"; "Mentorship for resilience".

Harnessing Personal Growth

Statements on "Highlighting expertise within team dynamics"; "Using my individuality to fill gaps in team expertise"; "Combining personal drive with shared team ambitions"; "Excellence within a team frame"; "Independently contributing to team unity"; "Shaping my role for team synergy"; "Crafting my place in team architecture".

Fostering Collaborative Individuality

Statements on "Embracing change for workplace agility"; "Flexibility navigating work uncertainties"; "Learning to pivot with new challenges"; "Proactively planning for disruption"; "Enhancing adaptability in evolving roles"; "Using adaptability for growth".

Cultivating Adaptive Assurance

Statements on "Optimizing tasks for better focus"; "Streamlining for mental clarity"; "Practicing present-minded productivity"; "Mindful breaks for performance upkeep"; "Prioritizing to manage energy"; "Refining routines for work-life balances".

Streamlining Workflows and Mindfulness

Statements on "Tailoring work-life balance for personal resilience"; "Building a supportive career-personal network"; "Setting boundaries for well-being"; "Cultivating a resilient work-life mindset"; "Aligning professional growth with life goals"; "Using workplace resources for life balance".

Streamlined Efficiency & Harmony

Statements on "Embracing empathy for deeper team connection"; "Sharing team goals for unity"; "Contributing to a positive team atmosphere"; "Valuing team downtime for bonding"; "Organizing social events to enhance camaraderie".

Fostering Resilience Work-Life Ecosystem

Statements on "Staying informed on support systems"; "Contributing to a resourceful team environment"; "Ensuring resource transparency"; "Tapping into wellness programs for resilience"; "Learning response protocols for crises"; "Seeking training to handle stress"; "Informed about workplace aids".

Creating Team Connectivity & Bonding

Statements on "Fostering constructive dialogue"; "Valuing active listening and communication"; "Initiating stress-reducing problem solving"; "Encouraging constructive feedback for growth"; "Embracing tough talks for progress"; "Welcoming diverse viewpoints for better understanding"; "Nurturing team dialogue for collective resilience".

Fortifying Resource Access & Response

Resource Empowerment & Engagement

Fostering Constructive Dialogue

Fig. 3. Data structure of enablers for overcoming employees' well-being shadows.

framework. The culmination of this process is illustrated in Figs. 1–3, which provide a visual representation of the final data structure.

## 4. Findings

Through inductive analysis, this study identified four main shadow experiences: erosion of interpersonal autonomy, surveillance-induced precarity, algorithmic bias dilemma, and personalized discontent. It also categorized well-being shadows into psychological alienation, physical adaptive overload, and social marginalization, clarifying the

mechanisms linking shadow experiences to these well-being impacts. Additionally, this study identified enablers for overcoming these shadows, such as agility and personal growth, streamlined efficiency, and resource empowerment. Pathways for addressing these issues include deepened introspection, empowered inner strength, and refined resourcefulness. The findings are shown in Figs. 4 and 5.

### 4.1. Experiences contributing to the shadows towards employee well-being

The implementation of AI-based HRM systems is frequently regarded

![](a71911ad87414271aeb190e0eebcb989_img.jpg)

SHADOW EXPERIENCES

INFLUENCING MECHANISMS

WELL-BEING SHADOW

Employee Well-Being

- Psychological Alienation
  - Impersonal job dissatisfaction.
  - Systemic depersonalization.
  - Uncertainty induced anxiety.
- Physical Adaptive Overload
  - Process-related exhaustion.
  - Chronic adaptation stress.
- Social Marginalization
  - Process driven isolation.
  - Support deficiency.
  - Procedural fairness skepticism.

Experiences Contributing to the employee well-being Shadows:

1. Erosion of Interpersonal Autonomy

1. Diminishing Trust and Cohesion
2. Loss of Empathy and Connection
3. Creativity and Innovation Suppression

2. Surveillance Induced Precarity

1. Heightened Power Imbalances
2. Identify Fragmentation
3. Diminished Intrinsic Motivation

3. Algorithm Bias Dilemma

1. Erosion of Fairness Perception
2. Legitimacy of Authorized Questioned
3. Compromised Adaptability and Learning

4. Personalized Discontentment

1. Mismatched Personalized Expectation
2. Stereotyping and Loss of Individuality
3. Limiting Personal Growth Loops

Fig. 4. Experiences Contributing to the employee well-being Shadows.

![](ecb25d766719ce041cf4cc390791a098_img.jpg)

ENABLERS OF CHANGE

OVERCOMING THE PATHWAYS

OVERCOMING THE SHADOWS

AGILITY AND PERSONAL GROWTH

- Harnessing reflective growth.
- Fostering collaborative individuality.
- Cultivating adaptive assurance.

STREAMLINED EFFICIENCY & HARMONY

- Streamlining workflows and mindfulness.
- Fostering resilient work-life ecosystems.
- Creating team connectivity and bonding.

RESOURCE EMPOWEREMENT & ENGAGEMENT

- Fortifying resource access and response.
- Fostering constructive dialogue.

DEEPENED INTROSPECTION

- Enhanced concentration.
- Established robust feedback mechanism.

EMPOWERED INNER POWER

- Boosted self-confidence.
- Strengthened confidence and security.
- Cultivate growth mindset.

REDEFINED RESOURCEFULNESS

- Unified individuality and teamwork.
- Increased adaptive skills.
- Enhanced mastery of resources.

PSYCHOLOGICAL ALIENATION

- Impersonal job dissatisfaction.
- Systemic depersonalization.
- Uncertainty induced anxiety.

PHYSICAL ADAPTIVE OVERLOAD

- Process-related exhaustion.
- Chronic adaptation stress.

SOCIAL MARGINALIZATION

- Process driven isolation.
- Support deficiency.
- Procedural fairness skepticism.

Fig. 5. Overcoming the employee well-being shadows.

as a means to enhance efficiency and objectivity within organizational structures. However, this study's investigation into a cohort of emerging technology-focused enterprises has uncovered several adverse effects on employee psycho-social integrity. This research critically examines the negative experiences associated with AI-based HRM systems, specifically highlighting the erosion of interpersonal autonomy, the emergence of surveillance-induced precarity, the conundrum of algorithmic bias, and the rise of individualized dissatisfaction.

#### 4.1.1. Erosion of interpersonal autonomy

At the forefront of these shadow experiences is the erosion of interpersonal autonomy. The ascendancy of AI within HRM has inadvertently catalyzed a significant reduction in employees' autonomous agency in interpersonal engagements. This erosion is evident in several areas. First, the reduction of human interaction occurs when employees engage with AI-mediated HRM functionalities. Although technological mediation streamlines processes, it inherently lacks the empathetic responsiveness characteristic of human HR interactions. One informant noted, "I feel like I am just a number now, not a person". This lack of personalized communication may lead employees to feel like mere data points rather than valued organizational members. Second, the undermining of professional autonomy becomes apparent as AI systems operationalize. The granular monitoring of performance metrics by AI imposes an unprecedented degree of oversight, fostering a perception of omnipresent surveillance. An employee expressed, "It feels like I am always being watched, with no room for creativity." This invasive scrutiny erodes employees' sense of professional autonomy, limiting space for innovative and discretionary engagement. Third, the impact on work relationships emerges as AI-driven practices shift from human-centric approaches. AI's focus on individual metrics can inadvertently marginalize collective effort and interpersonal support, which are essential for a vibrant workplace community. One participant shared, "Team spirit is fading because we are all isolated by the system's focus on individual performance." This realignment may lead to the breakdown of collegial relationships and the weakening of social cohesion needed for an effective and supportive work environment.

#### 4.1.2. Surveillance-induced precarity

The second shadow experience, surveillance-induced precarity, elucidates the pervasive fear caused by the omnipresent monitoring capabilities embedded within AI systems. This extends beyond mere privacy infringement, manifesting as a tangible encroachment into employees' lived realities, where the incessant data collection often merges professional and personal spheres. This phenomenon is primarily expressed through two aspects: the invasive nature of surveillance and anxiety about job displacement. First, privacy invasion and surveillance highlight the profound level of scrutiny AI systems exert over employee behavior and performance. The operational vigilance of these technologies can induce a panoptic effect, where employees internalize a sense of constant observation, fostering a workplace environment perceived as intrusive and overreaching. One employee remarked, "It feels like every move is being watched, even outside work hours." This intrusiveness raises legitimate concerns about the stewardship and potential exploitation of personal data, invoking a sense of vulnerability and unease among the workforces. Second, job displacement anxiety reflects the uncertainties caused by the growing reliance on AI for task automation. The issue of technological redundancy looms large as AI systems increasingly perform functions traditionally reserved for human personnel. An employee expressed, "I worry that one day, my job will be done by a machine." This transition engenders a palpable sense of insecurity among employees, who are aware of the potential obsolescence of their roles and experience apprehension about the continuity

and stability of their professional futures.

#### 4.1.3. Algorithmic bias dilemma

The third shadow experience in deploying AI within HRM systems is the algorithmic bias dilemma, posing a significant challenge to the integrity of automated decision-making processes. Despite the supposed impartiality and objectivity of algorithmic systems, the potential for bias and discriminatory outcomes remains a critical concern. This issue is characterized by two interrelated aspects: the propensity for bias and discrimination and the legal and ethical ambiguities associated with AI applications in HRM. First, the issue of bias and discrimination arises from recognizing that AI systems, despite their technological sophistication, are not free from the prejudices inherent in human judgment. These systems are products of human design, utilizing datasets filled with historical and systemic biases that can inadvertently inform their decision-making protocols. One employee expressed concern, stating, "I worry that the AI is making the same biased decisions that a person might but without any accountability." This awareness raises fears that algorithmic HRM may not only reflect but potentially amplify existing inequities within organizational practices, particularly in recruitment, promotion, and performance assessment.

Second, the legal and ethical ambiguity reflects the complex challenges AI applications pose to the established framework of labor legislation and ethical norms in the workplace. The "cold logic" of algorithms, while efficient at processing vast quantities of information, may fall short in navigating the intricate web of human relations and the nuanced moral considerations underpinning ethical decision-making in employment contexts. An employee noted, "It's hard to trust a system that can't understand the human side of things." This introduces uncertainty regarding the alignment of AI-driven HRM with existing legal standards and the broader ethical imperatives that govern fair and just employment practices.

#### 4.1.4. Personalized discontentment

The fourth shadow experience, personalized discontentment, pertains to how AI implementation in HRM affects individual employees' sense of well-being and value within the organizational setting. This experience manifests through three key factors: the erosion of engagement and morale, challenges of complexity and accessibility, and the ramifications of over-reliance on AI systems. First, decreased engagement and morale capture the psychological effects of interacting with AI-driven HRM systems perceived as impersonal or unjust. Such interactions can diminish employee morale, promoting a sense of devaluation and alienation. One employee stated, "I feel like I'm just part of a machine, not part of a team." As individuals perceive themselves as mere components within an automated framework, their engagement with the organizational vision and intrinsic motivation may be significantly undermined. Second, the complexity and accessibility of sophisticated AI systems highlight inherent difficulties. Employees lacking technological proficiency may struggle to navigate these systems, creating frustration and disenfranchisement. An employee remarked, "It's overwhelming to keep up with the technology, and I often feel left out." This technological barrier can exacerbate feelings of exclusion and inadequacy, negatively affecting overall well-being and the ability to contribute effectively in the workplace. Third, over-reliance on AI raises concerns about the marginalization of human judgment and expertise in decision-making. The growing dependence on algorithmic determinations could diminish the cultivation of human leadership attributes and marginalize insights from years of experiential knowledge. An employee expressed concern, saying, "We're losing the human touch that made us effective leaders." Such over-reliance threatens both individual well-being and organizational efficacy, as nuanced

comprehension and empathic leadership from human managers are neglected.

### 4.2. Shadow consequences on employee well-being

The in-depth analysis in this study has illuminated unforeseen and significant shadows that AI-driven HRM practices impose on employees' well-being across psychological, physical, and social domains.

#### 4.2.1. Psychological alienation

The psychological dimension of employee well-being is particularly vulnerable to AI-driven HRM. Three critical experiences are prominent: impersonal job dissatisfaction, systemic depersonalization, and uncertainty-induced anxiety.

Impersonal job dissatisfaction arises when AI assumes decision-making roles traditionally reliant on human insight, such as hiring and promotions. This leads to processes that make employees feel reduced to mere numbers and alienated from the organization's core values and their personal sense of job satisfaction. One employee noted, "Decisions sometimes feel detached like we're not fully seen." This alienation can erode commitment and loyalty, fostering an environment where employees feel underappreciated and expendable.

Systemic depersonalization occurs as workplaces increasingly rely on AI for HRM functions, threatening the personal engagement that once characterized them. As AI dominates analytics and decision-making, employees may feel deprived of individual acknowledgment and value. An employee commented, "It feels less personal; interactions are more automated." This shift can turn a lively environment into a sterile, mechanistic one, where employees see themselves as mere parts of a larger machine rather than integral components of a thriving community.

Uncertainty-induced anxiety stems from the lack of transparency in AI algorithms and their application in HR decisions. This opacity can lead employees to worry about their place and future in the company. One employee shared, "There's some concern about how AI evaluations might affect my role." Such anxiety may stifle creativity and drive as employees become more preoccupied with job security.

#### 4.2.2. Physical adaptive overload

Physical well-being is intricately connected to the work environment, and the rise of AI-driven HRM systems has introduced challenges in two key aspects: process-related exhaustion and chronic adaptation stress. Process-related exhaustion arises when employees are required to continuously engage with AI-managed workflows that may lack the nuance and flexibility of human-managed processes. This persistent interaction with impersonal systems can result in a sense of fatigue, affecting both mental and physical well-being. The demands for precision and adherence to digital protocols can be cognitively taxing, while prolonged stress and sedentary interactions contribute to physical discomfort. One employee remarked, "I feel more tired at the end of the day because of adapting to the system." This exhaustion can diminish job performance and adversely affect long-term health, leading to a cycle of reduced efficiency and increased absenteeism.

Chronic adaptation stress emerges from the ongoing pressure to adjust to AI-based systems, introducing a persistent form of stress that negatively impacts physical health. This stress is a continual experience, as employees must conform to algorithms dictating daily routines and career trajectories, often overlooking individuality or extenuating circumstances. An employee noted, "Adapting to the system's requirements sometimes feels challenging." Over time, this tension can compromise the immune system, exacerbate preexisting health conditions, and elevate risks for stress-related ailments, such as hypertension and heart disease.

#### 4.2.3. Social marginalization

Social well-being in the workplace is complex and multifaceted,

significantly influenced by the dynamics between employees and the systems governing their interactions. In the context of increasingly prevalent AI-based practices in HRM, social well-being is reflected in three key experiences: process-driven isolation, support deficiency, and procedural fairness skepticism. Process-driven isolation refers to how AI-driven workflows often reduce human-to-human interaction, as machines mediate communications and collaborations that were once direct. This technological shift can create a workplace where employees feel physically and psychologically isolated. One employee expressed, "I sometimes feel like I'm working in a bubble, cut off from my colleagues." This lack of interpersonal engagement hinders the development of strong work relationships and diminishes employees' sense of belonging and community, which is essential for a vibrant workplace culture.

Support deficiency arises from the inability of AI systems to replicate the emotional intelligence and empathetic presence of human HR professionals. AI systems often fail to provide the nuanced support employees need during challenging times. An employee noted, "When I needed guidance, the system just didn't understand my situation." This deficiency can foster an environment where employees feel unsupported and alone in managing their work-life complexities, potentially decreasing job satisfaction and increasing turnover.

Employees' trust in the fairness and transparency of AI-driven decision-making processes is crucial. However, the enigmatic nature of AI algorithms can lead to procedural fairness skepticism. Without clear understanding and communication, employees might suspect bias or oversimplification of complex human factors. One employee remarked, "I'm not sure if the system really considers all aspects of a situation." This can erode trust in the organization and its values, igniting feelings of injustice and disengagement.

### 4.3. The influencing mechanisms

This study's analysis also revealed how shadow experiences—the erosion of interpersonal autonomy, surveillance-induced precarity, algorithmic bias dilemma, and the sense of personalized discontent—detrimentially affect the well-being of employees in the psychological, physical, and social aspects.

#### 4.3.1. Erosion of interpersonal autonomy

This study observed that eroded interpersonal autonomy undermines employee well-being through a sequential process. This process begins with the undermining of trust and cohesion, continues with the loss of empathy and connection, and ultimately ends with the stifling of creativity and innovation.

The undermining of trust and cohesion is typically marked by the gradual degradation of interpersonal relationships. This degradation erodes the essential trust and mutual support that form the foundation of a productive and cohesive work environment. One employee mentioned, "It feels like the bonds we had are weakening."

With the deterioration of trust and cohesion, a rift can develop within the team and prompt feelings of isolation. The resulting decline in empathy and interpersonal connection exacerbates the disintegration of team cohesion. Another employee commented, "There's a growing sense of distance among us."

Finally, creativity and innovation are stifled. A team's weakened social bonds, stemming from a loss of trust and empathy, create an environment that is less hospitable to creative and innovative thought. The absence of an encouraging and collaborative environment consequently constrains the free flow of ideas, which is vital for fostering innovation. One participant remarked, "I sometimes hesitate to share new ideas."

#### 4.3.2. Surveillance-induced precarity

Surveillance-induced precarity can gradually affect employee well-being through several stages, which may amplify negative effects.

These stages might involve heightened power imbalances, identity fragmentation, and a reduction in intrinsic motivation.

In the context of power imbalances, surveillance in organizations can sometimes exacerbate existing disparities, potentially leading to workplace issues. Increased surveillance may empower those who monitor over those who are monitored, creating an environment where some employees feel scrutinized. One employee mentioned, “I occasionally feel like I am being watched, which can be unsettling.”

Regarding identity fragmentation, employees might experience a sense of self-disintegration due to power imbalances. Navigating constant surveillance, individuals may feel pressured to suppress parts of their identity to conform to oversight. This pressure can create internal dissonance and a disconnect with their genuine selves. An employee shared, “There are times I feel I cannot fully express myself at work.”

Intrinsic motivation may also be affected. When employees feel unable to express their true selves and face limitations due to surveillance, their motivation for work can decrease. This might impair performance and impact job satisfaction and psychological well-being, leading to a workforce that may be less engaged. One participant noted, “I have felt my enthusiasm for work wane at times, which can influence my performance.”

#### 4.3.3. Algorithm bias dilemma

The algorithm bias dilemma presents significant challenges to employee well-being by catalyzing a series of issues within organizational structures. This sequence begins with the perception of fairness being eroded, leads to the legitimacy of authority being questioned, and results in adaptability and learning being compromised.

The dilemma often starts when employees perceive an erosion of fairness due to algorithmic decision-making. This perception can swiftly diminish trust and morale, as individuals feel that impartiality in processes and outcomes is compromised. One employee expressed, “I sometimes feel the system does not treat everyone equally.” This perception can promote disillusionment and detachment, potentially unraveling workplace cohesion and commitment.

Following this, employees may begin to doubt the legitimacy of those in power. When the fairness of algorithms is scrutinized, the authority of individuals who implement and oversee these systems is inherently challenged. An employee commented, “I occasionally question whether leaders understand the full impact of these tools.” This growing skepticism can lead to a crisis of leadership, weakening the trust that underpins the acceptance of authority and potentially destabilizing organizational governance and hierarchical dynamics.

The repercussions of questioned authority and diminished perception of fairness reach a critical point where both organizational and individual adaptability and learning are compromised. The psychological safety that fuels innovation, risk-taking, and learning is undermined in an environment lacking trust. Employees may become risk-averse, reluctant to voice concerns or ideas, and resistant to change, stifling personal growth and organizational evolution. One participant noted, “I am careful about sharing new ideas because I’m unsure how they will be received.”

#### 4.3.4. Personalized discontentment

Personalized discontent can subtly undermine employee well-being, highlighting the nuanced challenges of ensuring personalization in the workplace. This adverse process begins with mismatched personalization expectations, advances to stereotyping and the loss of individuality, and culminates in limited personal growth loops.

Mismatched personalization expectations involve a dissonance between an individual’s anticipation of a tailored, considerate experience and the reality of an impersonal, one-size-fits-all approach. This mismatch can foster a sense of disillusionment. One employee observed, “I thought my needs would be considered, but it often feels generic.”

From this initial disconnect, organizations may inadvertently resort to broad categorizations or stereotyping to simplify personalization.

This misguided approach can prompt the loss of individuality, leading employees to feel pigeonholed and undervalued. An employee commented, “Sometimes, I feel like I’m just part of a category, not seen for my unique contributions.” This loss of individuality can further promote resentment and the feeling that employees are invisible within the organizational setting.

The loss of individuality can subsequently lead to the final stage of personalized discontent, involving limiting personal growth loops. Trapped within stereotype-driven expectations and roles, employees may enter cycles that stifle personal and professional development. These restrictive loops can reduce creativity, initiative, and the pursuit of individual aspirations, effectively limiting the potential for personal evolution and career progression. One participant noted, “Advancing seems challenging when you are confined to predefined roles.”

## 5. Discussion

This study explored the research question: How and why do the unintended consequences of AI-based HRM systems influence employee well-being within the organizational context? Through the inductive analysis, we identified four shadow experiences: the erosion of interpersonal autonomy, surveillance-induced precarity, algorithmic bias dilemma, and personalized discontentment. These shadow experiences highlight the unintended consequences of AI-based HRM systems. Additionally, we identified three categories of well-being shadows: psychological alienation, physical adaptive overload, and social marginalization. These categories represent the impacts of AI systems on employee well-being. We further identified enablers to transcend well-being shadows, which include agility and personal growth, streamlined efficiency and harmony, and resource empowerment and engagement. Finally, we outlined pathways for overcoming these shadows, which include deepened introspection, empowered inner power, and refined resourcefulness.

These findings contribute to addressing the research question by illustrating the interplay between shadow experiences, well-being impacts, and potential pathways for mitigating adverse effects. The study provides a comprehensive perspective on how AI-based HRM systems shape employee well-being within organizational contexts.

### 5.1. Theoretical contributions

This study makes several significant contributions to the theoretical understanding of AI-based HRM systems and their influence on employee well-being within organizational contexts.

First, this study advances the theoretical application of socio-technical systems theory to examine the dynamic and complex interactions between employees and AI-based HRM practices. Unlike prior research, which has predominantly employed psycho-social theories, fuzzy set theory, or data mining approaches to quantitatively analyze AI techniques and their benefits (Pan & Froese, 2023; Prikshat et al., 2023), this study shifts the focus to the nuanced relational processes underlying human-technology interactions (Del Giudice et al., 2023; Pereira et al., 2023; Simón et al., 2024). By employing socio-technical systems theory, the study develops a more holistic framework to capture the systemic and unintended consequences of AI-based HRM systems. This approach offers deeper insights into the interplay of technological and social elements, addressing the need for greater theoretical integration and qualitative research in the field of AI applications within organizations (Asatiani et al., 2021; Chubb, 2023).

Second, this study contributes to the literature by focusing on the dynamic and evolving unintended consequences of AI-based HRM systems and their implications for employee well-being. Prior studies have largely concentrated on static technological challenges (Cheng & Hackett, 2021; Pan & Froese, 2023; Prikshat et al., 2023), whereas this research examines the unfolding interplay between human and technological elements, highlighting shadow experiences such as the erosion

of interpersonal autonomy and surveillance-induced precarity. By uncovering these dynamic and systemic effects, the study enriches the scholarly understanding of the unintended consequences of AI integration in HRM systems. In doing so, it contributes to a more comprehensive understanding of how AI systems challenge traditional organizational dynamics and employee well-being, emphasizing both technological affordances and limitations (Bankins et al., 2024; Lee et al., 2023).

Third, this study offers a theoretical advancement by identifying the underlying mechanisms through which AI-based HRM systems influence employee well-being. While extant research has primarily focused on establishing relationships between AI-based HRM systems and employee outcomes (Gull et al., 2023; Shaikh et al., 2023; Xu et al., 2023), these studies often present a limited, static view of these interactions. By contrast, this study explores the complex, evolving nature of these mechanisms, capturing the contextual and temporal factors that shape employee experiences (Naeem et al., 2023; Van Looy, 2021). For example, the linkages between shadow experiences (e.g., algorithmic bias dilemmas) and well-being shadows (e.g., psychological alienation or physical adaptive overload) provide a nuanced understanding of how AI systems create ripple effects across multiple domains of employee well-being. This dynamic perspective advances theoretical frameworks by addressing the processes through which AI shapes organizational realities over time, enabling a more comprehensive understanding of these interactions for future research.

Finally, this study contributes by identifying enablers of change and pathways to mitigate the unintended consequences of AI-based HRM systems on employee well-being. While much of the existing literature emphasizes the outcomes of AI integration (Pan & Froese, 2023; Prikshat et al., 2023), it often neglects the processes and strategies for addressing the challenges posed by these technologies. This study addresses this gap by introducing enablers, such as agility and personal growth, streamlined efficiency and harmony, and resource empowerment and engagement, which highlight actionable mechanisms for reducing the adverse effects of AI on employee well-being. Furthermore, the pathways identified—such as deepened introspection, empowered inner power, and refined resourcefulness—offer a roadmap for organizations to navigate and transcend the challenges of AI integration. These contributions address the paradoxes of AI in management (Arslan et al., 2022; Raisch & Krakowski, 2021; Shepherd & Majchrzak, 2022) and provide actionable insights for balancing the organizational benefits of AI with its potential drawbacks, thus advancing theoretical and practical discussions on the ethical and effective application of AI in HRM contexts.

### 5.2. Managerial implications

The findings of this study offer significant insights for managers on how to effectively implement AI-based HRM systems while mitigating their adverse impacts on employee well-being. There are several implications that could be useful for managers.

First, managers should ensure transparency and employee involvement in the implementation of AI systems. Transparent communication about the purpose, scope, and processes of AI-based HRM systems helps foster trust and reduces uncertainty among employees. Involving employees in decisions regarding AI deployment, particularly in areas such as performance monitoring, recruitment, and task allocation, can minimize feelings of surveillance-induced precarity and the erosion of interpersonal autonomy.

Second, managers should address algorithmic biases and ensure fairness in AI-driven decision-making processes. Regular audits of AI systems used in HR functions, such as hiring, promotions, and performance evaluations, are essential to identify and mitigate biases. To promote fairness and inclusivity, AI-driven decisions should always include human oversight to account for contextual and subjective factors, ensuring employees perceive the processes as equitable and

trustworthy.

Third, managers should balance the use of AI with human interaction to prevent psychological alienation among employees. While AI tools can optimize HR processes and increase efficiency, over-reliance on technology can isolate employees and diminish meaningful interpersonal connections. Managers should actively encourage collaboration and human interaction in the workplace to ensure that AI complements, rather than replaces, relationships. For example, creating opportunities for team-building activities and fostering direct communication can help counteract feelings of social marginalization.

Fourth, managers should provide employees with adequate resources and training to adapt to AI systems effectively. Offering training programs, workshops, and ongoing technical support can empower employees to engage confidently with AI tools. This approach reduces resistance to AI adoption and allows employees to view technological advancements as opportunities for personal growth and efficiency, fostering resource empowerment and skill development.

### 5.3. Limitations and future research directions

This study provides valuable insights into the influence of AI-based HRM systems on employee well-being in seasoned entrepreneurial firms. However, there are several limitations that should be acknowledged, which also pave the way for future research directions. First, the study is limited to seasoned entrepreneurial firms in the high-technology sector, which may restrict the generalizability of the findings to other organizational contexts. While these firms provide a unique combination of innovation and maturity, organizations in other industries or at different stages of development may experience different challenges and outcomes related to AI adoption. Future research should explore diverse organizational settings, such as public sector organizations, small startups, or traditional industries, to examine whether the identified shadow experiences and well-being outcomes vary across contexts.

Second, this research employs a comparative case study design involving six high-technology ventures. While this approach allows for an in-depth exploration of human-technology interactions, the limited number of cases may not capture the full diversity of experiences across organizations. Expanding the number of cases or conducting large-scale, multi-industry studies could help validate and generalize the findings. Additionally, mixed-methods approaches that combine qualitative and quantitative analyses could provide a more comprehensive understanding of the nuanced mechanisms and measurable impacts of AI-based HRM systems.

Third, the study primarily focuses on the adverse effects of AI-based HRM systems, identifying shadow experiences and proposing mitigation strategies. While these findings are critical, there is less emphasis on the positive and transformative potential of AI in enhancing employee well-being. Future research should adopt a balanced approach by exploring how AI-based HRM systems can proactively foster positive outcomes, such as personal growth, creativity, and collaboration, in addition to addressing unintended consequences.

Fourth, while this study identifies mechanisms linking shadow experiences to well-being outcomes, it does not delve deeply into the design and functionality of specific AI algorithms or systems. Future research should take a more technical perspective, examining how the features of AI systems—such as transparency, explainability, and adaptability—affect employee perceptions and outcomes. This could provide actionable insights for designing human-centered AI systems that align with employee well-being goals.

To address these limitations and pursue these research directions, future studies can build on the insights provided here to develop a more comprehensive understanding of the evolving role of AI in HRM and its implications for employee well-being.

## CRediT authorship contribution statement

**Jianwen Zheng:** Writing – original draft, Methodology, Investigation, Conceptualization. **Justin Zuopeng Zhang:** Writing – original draft, Methodology, Investigation, Conceptualization. **Muhammad Mustafa Kamal:** Writing – review & editing. **Xiaoyang Liang:** Writing – original draft, Methodology, Investigation, Formal analysis, Conceptualization. **Ebtesam Abdullah Alzeiby:** Writing – review & editing.

## Acknowledgement

Princess Nourah bint Abdulrahman University Researchers Supporting Project number (PNURSP2025R727), Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia.

## Data availability

Data will be made available on request.

## References

Abubakar, A. M., Behravesh, E., Rezapouraghdam, H., & Yildiz, S. B. (2019). Applying artificial intelligence technique to predict knowledge hiding behavior. *International Journal of Information Management*, 49, 45–57.

Akhtar, P., Ghouri, A. M., Khan, H. U. R., Amin ul Haq, M., Awan, U., Zahoor, N., & Ashraf, A. (2023). Detecting fake news and disinformation using artificial intelligence and machine learning to avoid supply chain disruptions. *Annals of Operations Research*, 327(2), 633–657.

Alam, M. K. (2021). A systematic qualitative case study: Questions, data collection, NVivo analysis and saturation. *Qualitative Research in Organizations and Management: An International Journal*, 16(1), 1–31.

Arslan, A., Cooper, C., Khan, Z., Golgeci, I., & Ali, I. (2022). Artificial intelligence and human workers interaction at team level: A conceptual assessment of the challenges and potential HRM strategies. *International Journal of Management*, 43(1), 75–88.

Asatiani, A., Malo, P., Nagbol, P. R., Penttinen, E., Rinta-Kahila, T., & Salovaara, A. (2021). Socio-technical envelment of artificial intelligence: An approach to organizational deployment of inscrutable artificial intelligence systems. *Journal of the Association for Information Systems*, 22(2), 325–352.

Awan, U., Gölgeci, I., Makhmadshoev, D., & Mishra, N. (2022). Industry 4.0 and circular economy in an era of global value chains: What have we learned and what is still to be explored? *Journal of Cleaner Production*, 371, Article 133621.

Bankins, S., Ocampo, A. C., Marrone, M., Restubog, S. L. D., & Woo, S. E. (2024). A multilevel review of artificial intelligence in organizations: Implications for organizational behavior research and practice. *Journal of Organizational Behavior*, 45 (2), 159–182.

Berraies, S., Lajili, R., & Chitoui, R. (2020). Social capital, employees' well-being and knowledge sharing: Does enterprise social networks use matter? Case of Tunisian knowledge-intensive firms. *Journal of Intellectual Capital*, 21(6), 1153–1183. <https://doi.org/10.1108/JIC-01-2020-00112>

Cannas, V. G., Ciano, M. P., Saltalamacchia, M., & Secchi, R. (2024). Artificial intelligence in supply chain and operations management: A multiple case study research. *International Journal of Production Research*, 62(9), 3333–3360.

Cheng, M. M., & Hackett, R. D. (2021). A critical review of algorithms in HRM: Definition, theory, and practice. *Human Resource Management Review*, 31(1), Article 100698. <https://doi.org/10.1016/j.hrmr.2019.100698>

Chowdhury, S., Budhwar, P., Dey, P. K., Joel-Edgar, S., & Abadie, A. (2022). AI-employee collaboration and business performance: Integrating knowledge-based view, socio-technical systems and organisational socialisation framework. *Journal of Business Research*, 144, 31–49.

Chowdhury, S., Dey, P., Joel-Edgar, S., Bhattacharya, S., Rodriguez-Espindola, O., Abadie, A., & Truong, L. (2023). Unlocking the value of artificial intelligence in human resource management through AI capability framework. *Human Resource Management Review*, 33(1), Article 100899. <https://doi.org/10.1016/j.hrmr.2022.100899>

Chubb, L. A. (2023). Me and the machines: Possibilities and pitfalls of using artificial intelligence for qualitative data analysis. *International Journal of Qualitative Methods*, 22, Article 16094069231193593.

Connelly, C. E., Fieseler, C., Cerne, M., Giessner, S. R., & Wong, S. I. (2021). Working in the digitized economy: HRM theory & practice. *Human Resource Management Review*, 31(1), Article 100762.

Cubric, M. (2020). Drivers, barriers and social considerations for AI adoption in business and management: A tertiary study. *Technology in Society*, 62, Article 101257.

Del Giudice, M., Scutotto, V., Orlando, B., & Mustilli, M. (2023). Toward the human-centered approach: A revised model of individual acceptance of AI. *Human Resource Management Review*, 33(1), Article 100856.

Dutta, D., & Mishra, S. K. (2024). Bots for mental health: The boundaries of human and technology agencies for enabling mental well-being within organizations. *Perso*nal Review, 53(5), 1129–1156.

Eisenhardt, K. M. (1989). Building theories from case study research. *Academy of Management Review*, 14(4), 532–550. <https://doi.org/10.2307/258557>

Eisenhardt, K. M. (2021). What is the Eisenhardt Method, really? *Strategic Organization*, 19(1), 147–160.

Eisenhardt, K. M., & Graeber, M. E. (2007). Theory building from cases: Opportunities and challenges. *Academy of Management Journal*, 50(1), 25–32. <https://doi.org/10.5465/ajm.2007.24160888>

Fox, K. E., Johnson, S. T., Berkman, L. F., Sianoja, M., Soh, Y., Kubzansky, L. D., & Kelly, E. L. (2022). Organisational-and group-level workplace interventions and their effect on multiple domains of worker well-being: A systematic review. *Work & Stress*, 36(1), 30–59. <https://doi.org/10.1080/02678373.2021.1969476>

Glaser, B., & Strauss, A. (2017). *Discovery of grounded theory: Strategies for qualitative research*. Routledge.

Grewal, D., Benoit, S., Noble, S. M., Guha, A., Ahlholm, C. P., & Nordfält, J. (2023). Leveraging in-store technology and AI: Increasing customer and employee efficiency and enhancing their experiences. *Journal of Retailing*.

Guest, D. E. (2017). Human resource management and employee well-being: Towards a new analytic framework. *Human Resource Management Journal*, 27(1), 22–38. <https://doi.org/10.1111/1748-8583.12139>

Guest, D., Knox, A., & Warhurst, C. (2022). Humanizing work in the digital age: Lessons from socio-technical systems and quality of working life initiatives. *Human relations*, 75(8), 1461–1482.

Guinan, P. J., Parise, S., & Langowitz, N. (2019). Creating an innovative digital project team: Levers to enable digital transformation. *Business Horizons*, 62(6), 717–727.

Gull, A., Ashfaq, J., & Aslam, M. (2023). AI in the Workplace: Uncovering Its Impact on Employee Well-being and the Role of Cognitive Job Insecurity. *International Journal of Business & Economic Affairs (LIBEA)*, 8(4).

Halid, H., Ravesangar, K., Mahadzir, S. L., & Halim, S. N. A. (2024). Artificial Intelligence (AI) in Human Resource Management (HRM). In *Building the Future with Human Resource Management* (pp. 37–70). Cham: Springer International Publishing.

Halkias, D., Neubert, M., Thurman, P. W., & Harkiolakis, N. (2022). The multiple case study design: Methodology and application for management education. Routledge.

Hennink, M., Hutter, I., & Bailey, A. (2020). *Qualitative research methods*. Sage.

Ho, B. Q., Otsuki, M., Kishita, Y., Kobayakawa, M., & Watanabe, K. (2022). Human augmentation technologies for employee well-being: A research and development agenda. *International Journal of Environmental Research and Public Health*, 19(3), 1195.

Inceoglu, I., Thomas, G., Chu, C., Plans, D., & Gerbas, A. (2018). Leadership behavior and employee well-being: An integrated review and a future research agenda. *The Leadership Quarterly*, 29(1), 179–202. <https://doi.org/10.1016/j.leaq.2017.12.006>

Kinowska, H., & Sienkiewicz, L. J. (2023). Influence of algorithmic management practices on workplace well-being–evidence from European organisations. *Information Technology & People*, 36(8), 21–42. <https://doi.org/10.1108/ITP-02-2022-0079>

Konuk, H., Ataman, G., & Kambur, E. (2023). The effect of digitalized workplace on employees' psychological well-being: Digital Taylorism approach. *Technology in Society*, 47(4).

Lee, M. C., Scheepers, H., Lui, A. K., & Ngai, E. W. (2023). The implementation of artificial intelligence in organizations: A systematic literature review. *Information & Management*, 60(5), Article 103816.

P. Leonardi, N. Contractor Better people analytics Harv. Bus. Rev., 96 (6) (2018), pp. 70–81.

Maity, S. (2019). Identifying opportunities for artificial intelligence in the evolution of training and development practices. *Journal of Management Development*, 38(8), 651–663.

Makarius, E. E., Mukherjee, D., Fox, J. D., & Fox, A. K. (2020). Rising with the machines: A socio-technical framework for bringing artificial intelligence into the organization. *Journal of business research*, 120, 262–273.

Malik, A., Budhwar, P., Mohan, H., & Nr., S. (2023). Employee experience—the missing link for engaging employees: Insights from an MNE's AI-based HR ecosystem. *Human Resource Management*, 62(1), 97–115.

Manz, C. C., & Stewart, G. L. (1997). Attaining flexible stability by integrating total quality management and socio-technical systems theory. *Organization Science*, 8(1), 59–70.

Münch, C., Marx, E., Benz, L., Hartmann, E., & Matzner, M. (2022). Capabilities of digital servitization: Evidence from the socio-technical systems theory. *Technological Forecasting and Social Change*, 176, Article 121361.

Naem, M., Ozuem, W., Howell, K., & Ranfagni, S. (2023). A step-by-step process of thematic analysis to develop a conceptual model in qualitative research. *International Journal of Qualitative Methods*, 22, Article 1609406923120579.

Nazareno, L., & Schiff, D. S. (2021). The impact of automation and artificial intelligence on worker well-being. *Technology in Society*, 67, Article 101679. <https://doi.org/10.1016/j.techsoc.2021.101679>

OECD (2023). *OECD guidelines on measuring subjective well-being*. <https://www.oecd.org/wise/oecd-guidelines-on-measuring-subjective-well-being-9789264191655-en.htm>

Ore, O., & Sposato, M. (2022). Opportunities and risks of artificial intelligence in recruitment and selection. *International Journal of Organizational Analysis*, 30(6), 1771–1782.

Pan, Y., & Froese, F. J. (2023). An interdisciplinary review of AI and HRM: Challenges and future directions. *Human Resource Management Review*, 33(1), Article 100924.

Patton, M. Q. (2015). *Qualitative Research & Evaluation Methods* (4th ed.). Thousand Oaks, CA: SAGE Publications.

Pereira, V., Hadjelias, E., Christofi, M., & Vrontis, D. (2023). A systematic literature review on the impact of artificial intelligence on workplace outcomes: A multi-process perspective. *Human Resource Management Review*, 33(1), Article 100857.

Prikschat, V., Islam, M., Patel, P., Malik, A., Budhwar, P., & Gupta, S. (2023). AI-Augmented HRM: Literature review and a proposed multilevel framework for future research. *Technological forecasting and Social Change, 193*, Article 122645.

Prikschat, V., Malik, A., & Budhwar, P. (2023). AI-augmented HRM: Antecedents, assimilation and multilevel consequences. *Human Resource Management Review, 33* (1), Article 100860.

Raisch, S., & Krakowski, S. (2021). Artificial intelligence and management: The automation–augmentation paradox. *Academy of Management Review, 46*(1), 192–210.

Robert, L. P., Pierce, C., Marquis, L., Kim, S., & Alahmad, R. (2020). Designing fair AI for managing employees in organizations: A review, critique, and design agenda. *Human-Computer Interaction, 35*(5–6), 545–575.

Rodgers, W., Murray, J. M., Stefanidis, A., Degbey, W. Y., & Tarba, S. Y. (2023). An artificial intelligence algorithmic approach to ethical decision-making in human resource management processes. *Human Resource Management Review, 33*(1), Article 100925.

Reiff, C. D., & Keyes, C. L. M. (1995). The structure of psychological well-being revisited. *Journal of Personality and Social Psychology, 69*(4), 719. <https://doi.org/10.1037/0022-3514.69.4.719>

Shaikh, F., Afshan, G., Anwar, R. S., Abbas, Z., & Chana, K. A. (2023). Analyzing the impact of artificial intelligence on employee productivity: The mediating effect of knowledge sharing and well-being. *Asia Pacific Journal of Human Resources, 61*(4), 794–820.

Shepherd, D. A., & Majchrzak, A. (2022). Machines augmenting entrepreneurs: Opportunities (and threats) at the Nexus of artificial intelligence and entrepreneurship. *Journal of Business Venturing, 37*(4), Article 106227.

Simón, C., Revilla, E., & Sáenz, M. J. (2024). Integrating AI in organizations for value creation through Human-AI teaming: A dynamic-capabilities approach. *Journal of Business Research, 182*, Article 114783.

Sony, M., & Naik, S. (2020). Industry 4.0 integration with socio-technical systems theory: A systematic review and proposed theoretical model. *Technology in Society, 61*, Article 101248.

Tracy, S. J. (2024). Qualitative research methods: Collecting evidence, crafting analysis, communicating impact. John Wiley & Sons.

Van Esch, P., & Black, J. S. (2019). Factors that influence new generation candidates to engage with and complete digital, AI-enabled recruiting. *Business Horizons, 62*(6), 729–739.

Van Looy, A. (2021). A quantitative and qualitative study of the link between business process management and digital innovation. *Information & Management, 58*(2), Article 103413.

Warr, P. (1990). The measurement of well-being and other aspects of mental health. *Journal of Occupational, 63*(3), 193–210. <https://doi.org/10.1111/j.2044-8325.1990.tb00521.x>

Xiao, Q., Yan, J., & Bamber, G. J. (2023). How does AI-enabled HR analytics influence employee resilience: Job crafting as a mediator and HRM system strength as a moderator. *Personnel Review*.

Xu, G., Xue, M., & Zhao, J. (2023). The relationship of artificial intelligence opportunity perception and employee workplace well-being: A moderated mediation model. *International Journal of Environmental Research and Public Health, 20*(3), 1974.

Yang, C. H. (2022). How artificial intelligence technology affects productivity and employment: Firm-level evidence from Taiwan. *Research Policy, 51*(6), Article 104536.

Yin, R. K. (2009). *Case study research: Design and methods* (Vol. 5). Sage.

Yu, X., Xu, S., & Ashton, M. (2023). Antecedents and outcomes of artificial intelligence adoption and application in the workplace: The socio-technical system theory perspective. *Information Technology & People, 36*(1), 454–474.

Zahoor, N., Donbesur, F., Christofi, M., & Miri, D. (2022). Technological innovation and employee psychological well-being: The moderating role of employee learning orientation and perceived organizational support. *Technological Forecasting and Social Change, 179*, Article 121610.

model. *Journal of Occupational Health Psychology, 23*(2), 262. <https://doi.org/10.1037/ocp0000070>

Giermild, L. M., Strich, F., Christ, O., Leicht-Deobald, U., & Redzepi, A. (2022). The dark sides of people analytics: Reviewing the perils for organisations and employees. *European Journal of Information Systems, 31*(3), 410–435. <https://doi.org/10.1080/0960085X.2021.1927213>

Gilbreath, B., & Benson, P. G. (2004). The contribution of supervisor behaviour to employee psychological well-being. *Work & Stress, 18*(3), 255–266. <https://doi.org/10.1080/0267837041233137499>

Halbesleben, J. R. (2010). A meta-analysis of work engagement: Relationships with burnout, demands, resources, and consequences. In *Work engagement: A handbook of essential theory and research* (1st ed., Vol. 8, pp. 102–117). Psychology Press.

Jong, T., Wiezer, N., Weerd, M., Nielsen, K., Mattila-Holappa, P., & Mockalio, Z. (2016). The impact of restructuring on employee well-being: A systematic review of longitudinal studies. *Work & Stress, 30*(1), 91–114. <https://doi.org/10.1080/02678373.2015.1136710>

Jonge, J., & Schaufeli, W. B. (1998). Job characteristics and employee well-being: A test of Warr's Vitamin Model in health care workers using structural equation modelling. *Journal of Organizational Behavior: The International Journal of Industrial, Occupational and Organizational Psychology and Behavior, 19*(4), 387–407.

Kelloway, E. K., Turner, N., Barling, J., & Loughlin, C. (2012). Transformational leadership and employee psychological well-being: The mediating role of employee trust in leadership. *Work & Stress, 26*(1), 39–55. <https://doi.org/10.1080/02678373.2012.660774>

Kompier, M., Ybema, J. F., Janssen, J., & Taris, T. (2009). Employment contracts: Cross-sectional and longitudinal relations with quality of working life, health and well-being. *Journal of Occupational Health, 51*(3), 193–203. <https://doi.org/10.1539/joh.L8150>

Kong, H., Yin, Z., Baruch, Y., & Yuan, Y. (2023). The impact of trust in AI on career sustainability: The role of employee-AI collaboration and protean career orientation. *Journal of Vocational Behavior, 146*, Article 103928. <https://doi.org/10.1016/j.jvb.2023.103928>

Leicht-Deobald, U., Busch, T., Schank, C., Weibel, A., Schaufeli, S., Wildhaber, L., & Kasper, G. (2019). The challenges of algorithm-based HR decision-making for personal integrity. *Journal of Business Ethics, 160*(2), 377–392. <https://doi.org/10.1007/s10551-019-04204-w>

Lesener, T., Gusev, B., & Wolter, C. (2019). The job demands-resources model: A meta-analytic review of longitudinal studies. *Work & Stress, 33*(1), 76–103. <https://doi.org/10.1080/02678373.2018.1529065>

Mäkiikangas, A., Feldt, T., & Kinnunen, U. (2007). Warr's scale of job-related affective well-being: A longitudinal examination of its structure and relationships with work characteristics. *Work & Stress, 21*(3), 197–219. <https://doi.org/10.1080/02678370701662151>

Mazzetti, G., Robledo, E., Vignoli, M., Topa, G., Guglielmi, D., & Schaufeli, W. B. (2023). Work engagement: A meta-analysis using the job demands-resources model. *Psychological Reports, 126*(3), 1069–1107. <https://doi.org/10.1177/004112110519888>

Meijerink, J. G., Beijer, S. E., & Bos-Nehles, A. C. (2021). A meta-analysis of mediating mechanisms between employee reports of human resource management and employee performance: Different pathways for descriptive and evaluative reports? *The International Journal of Human Resource Management, 32*(2), 394–442. <https://doi.org/10.1080/09585102.2020.1810737>

Meijerink, J. G., & Bondarouk, T. (2023). The duality of algorithmic management: Toward a research agenda on HRM algorithms, autonomy and value creation. *Human Resource Management Review, 33*(1), Article 100876. <https://doi.org/10.1016/j.hrmr.2021.100876>

Radonjić, A., Duarte, H., & Pereira, N. (2022). Artificial intelligence and HRM: HR managers' perspective on decisiveness and challenges. *European Management Journal, 41*(4), 66–83. <https://doi.org/10.1177/0088125619862257>

Schaufeli, W. B. (2017). Applying the job demands-resources model. *Organizational Dynamics, 2*(46), 120–132. <https://doi.org/10.1016/j.ordyn.2017.04.008>

Shrestha, Y. R., Ben-Menahem, S. M., & Krogh, G. (2019). Organizational decision-making structures in the age of artificial intelligence. *California Management Review, 61*(4), 66–83. <https://doi.org/10.1177/0008125619867910>

Tompru, M., & Lee, M. K. (2022). Employment relationships in algorithmic management: A psychological contract perspective. *Computers in Human Behavior, 126*, Article 106997. <https://doi.org/10.1016/j.chb.2021.106997>

Warr, P. (1987). *Work, unemployment, and mental health*. Oxford University Press.

Zheng, X., Zhu, W., Zhao, H., & Zhang, C. (2015). Employee well-being in organizations: Theoretical model, scale development, and cross-cultural validation. *Journal of Organizational Behavior, 36*(5), 621–644.

Zhou, Y., Wang, L., & Chen, W. (2023). The dark side of AI-enabled HRM on employees based on AI algorithmic features. *Journal of Organizational Change Management, 36* (7), 1222–1241.

## Further reading

Baiocco, S., Fernández-Macías, E., Rani, U., & Pesole, A. (2022). *The Algorithmic Management of work and its implications in different contexts*. JRC Working Papers Series on Labour, Education and Technology.

Bakker, A., & Demerouti, E. (2007). The job demands-resources model: State of the art. *Journal of Managerial Psychology, 22*(3), 309–328. <https://doi.org/10.1108/02683940710733115>

Basu, S., Majumdar, B., Mukherjee, K., Munjal, S., & Palaksha, C. (2023). Artificial intelligence-HRM interactions and outcomes: A systematic review and causal configurational explanation. *Human Resource Management Review, 33*(1), Article 100893.

Brauchli, R., Schaufeli, W. B., Jenny, G. J., Füllemann, D., & Bauer, G. F. (2013). Disentangling stability and change in job resources, job demands, and employee well-being—A three-wave study on the Job-Demands Resources model. *Journal of Vocational Behavior, 83*(2), 117–129. <https://doi.org/10.1016/j.jvb.2013.03.003>

Bustamante, M., & Gandhi, N. (2018). *Human resources in the age of automation*. https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-organization-blog/how-to-get-the-most-from-end-of-year-reviews.

Carnevale, J. B., & Hatak, I. (2020). Employee adjustment and well-being in the era of COVID-19: Implications for human resource management. *Journal of Business Research, 116*, 183–187. <https://doi.org/10.1016/j.jbusres.2020.05.037>

Dicke, T., Stebner, F., Linninger, C., Kunter, M., & Leutner, D. (2018). A longitudinal study of teachers' occupational well-being: Applying the job demands-resources

Jianwen Zheng is an Assistant Professor at Xian Jiaotong-Liverpool University. His research areas include innovation and entrepreneurship.

Justin Zuopeng Zhang is a faculty member in the Coggin College of Business at the University of North Florida. He received his Ph.D. in Business Administration with a concentration on Management Science and Information Systems from Pennsylvania State University, University Park. His research interests include economics of information

systems, knowledge management, electronic business, business process management, information security, and social networking.

**Muhammad Mustafa Kamal** is an Associate Professor in Sustainable Operations and Analytics & Deputy Head of Department for Operations and Analytics, University of Exeter, UK. His areas of specialism are Supply Chain Digitalisation. Other research interests include Circular Economy, Operations Management, Industry 4.0/5.0, Disruptive Technologies, Information Systems and Technology Management, Social Media, Big Data and Business Analytics.

**Xiaoyang Liang** is an Assistant Professor at Xi'an Jiaotong Liverpool University (XJTLLU). Her research areas include Sustainable HRM, business ethics, CSR, and leadership. Her work has been published in Asia Pacific Journal of Management, Personnel Review, Journal of Global Information Management, Journal of Advanced Nursing, Nursing Ethics, Nonprofit Management and Leadership and others.

**Ebtesam Abdullah Alzeiby** is currently an associate professor in Princess Nourah bint Abdulrahman University, Saudi Arabia. Her research interests include well-being, cyberpsychology, and psychological measures. Her research has appeared in the International Journal of Therapy and Rehabilitation, Child Care in Practice and Technological Forecasting and Social Change.